<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <title>GettingStartedKubernetes • Vitess</title>
    <meta name="description" content="This page explains how to start a Kubernetes cluster and also run
Vitess on Kubernetes. This example was most recently tested using
the binary release of Kubernetes v0.9.1.

Prerequisites

To complete the exercise in this guide, you must locally install Go 1.3+,
Vitess&#39; vtctlclient tool, and Google Cloud SDK. The
following sections explain how to set these up in your environment.

Install Go 1.3+

You need to install Go 1.3+ to build the
vtctlclient tool, which issues commands to Vitess.

After installing Go, make sure your GOPATH environment
variable is set to the root of your workspace. The most common setting
is GOPATH=$HOME/go, and the value should identify a
directory to which your non-root user has write access.

In addition, make sure that $GOPATH/bin is included in
your $PATH. More information about setting up a Go
workspace can be found at
http://golang.org/doc/code.html#Organization.

Build and install vtctlclient

The vtctlclient tool issues commands to Vitess.
$ go get git￼￼hub.com/youtube/vitess/go/cmd/vtctlclient

This command downloads and builds the Vitess source code at:
$GOPATH/src/github.com/youtube/vitess/

It also copies the built vtctlclient binary into $GOPATH/bin.

Set up Google Compute Engine, Container Engine, and Cloud tools

To run Vitess on Kubernetes using Google Compute Engine (GCE),
you must have a GCE account with billing enabled. The instructions
below explain how to enable billing and how to associate a billing
account with a project in the Google Developers Console.


Log in to the Google Developers Console to enable billing.


 Click the Billing pane if you are not there already.
 Click New billing account
 Assign a name to the billing account -- e.g. &quot;Vitess on
Kubernetes.&quot; Then click Continue. You can sign up
for the free trial
to avoid any charges.

Create a project in the Google Developers Console that uses
your billing account:


 In the Google Developers Console, click the Projects pane.
 Click the Create Project button.
 Assign a name to your project. Then click the Create button.
Your project should be created and associated with your
billing account. (If you have multiple billing accounts,
confirm that the project is associated with the correct account.)
 After creating your project, click APIs &amp; auth in the left menu.
 Click APIs.
 Find Google Compute Engine and Google Container Engine API
and click the OFF button for each to enable those two APIs.

Follow the GCE quickstart guide to set up
and test the Google Cloud SDK. You will also set your default project
ID while completing the quickstart. Start with step 2 in the setup
process.

Note: During the quickstart, you&#39;ll generate an SSH key for
Google Compute Engine, and you will be prompted to enter a
passphrase. You will be prompted for that passphrase several times
when bringing up your Kubernetes cluster later in this guide.


Start a Kubernetes cluster


Set the KUBECTL environment variable to point to the
gcloud command:
$ export KUBECTL=&#39;gcloud preview container kubectl&#39;

Enable preview features in the gcloud tool:
$ gcloud components update preview

If you did not complete the GCE quickstart guide, set
your default project ID by running the following command.
Replace PROJECT with the project ID assigned to your
Google Developers Console
project. You can find the ID
by navigating to the Overview page for the project
in the Console.
$ gcloud config set project PROJECT

Set the zone
that your installation will use:
$ gcloud config set compute/zone us-central1-b

Create a Kubernetes cluster:
$ gcloud preview container clusters create example --machine-type n1-standard-1 --num-nodes 3

While the cluster is starting, you will be prompted several
times for the passphrase you created while setting up Google
Compute Engine.
The command&#39;s output includes the URL for the Kubernetes master server:
endpoint: 146.148.70.28
masterAuth:
password: YOUR_PASSWORD
user: admin


 Open the endpoint URL in a browser to get the full effect
of the &quot;Hello World&quot; experience in Kubernetes.
 If you see a ERRCERTAUTHORITY_INVALID error
indicating that the server&#39;s security certificate is not
trusted by your computer&#39;s operating system, click the
Advanced link and then the link to proceed to the URL.
 You should be prompted to enter a username and password to
access the requested page. Enter the masterAuth
username and password from the gcloud command&#39;s
output.



Start a Vitess cluster


Navigate to your local Vitess source code

This directory would have been created when you installed
vtctlclient:
$ cd $GOPATH/src/github.com/youtube/vitess

Start an etcd cluster:
$ cd examples/kubernetes
vitess/examples/kubernetes$ ./etcd-up.sh

This command creates two clusters. One is for the global cell,
and the other is for the test cell. You can check the status
of the pods
in the cluster by running:
$KUBECTL get pods

It may take a while for each Kubernetes minion to download the
Docker images the first time it needs them. While the images
are downloading, the pod status will be Pending.

Note: In this example, each script that has a name ending in
-up.sh also has a corresponding -down.sh
script, which can be used to stop certain components of the
Vitess cluster without bringing down the whole cluster. For
example, to tear down the etcd deployment, run:
vitess/examples/kubernetes$ ./etcd-down.sh

Start vtctld

The vtctld server provides a web interface to
inspect the state of the Vitess cluster. It also accepts RPC
commands from vtctlclient to modify the cluster.
vitess/examples/kubernetes$ ./vtctld-up.sh

To let you access vtctld from outside Kubernetes,
the vtctld service is created with the
createExternalLoadBalancer option. This is a
convenient shortcut
for cloud providers that support external load balancers.
On supported platforms, Kubernetes will then automatically
create an external IP that load balances onto the pods
comprising the service.
Access vtctld

To access the vtctld service from outside
Kubernetes, you need to open port 15000 on the GCE firewall.
(If you don&#39;t complete this step, the only way to issue commands
to vtctld would be to SSH into a Kubernetes node
and install and run vtctlclient there.)
$ gcloud compute firewall-rules create vtctld --allow tcp:15000

Then, get the address of the load balancer for vtctld:
$ gcloud compute forwarding-rules list
NAME   REGION      IP_ADDRESS    IP_PROTOCOL TARGET
vtctld us-central1 104.154.64.12 TCP         us-central1/targetPools/vtctld

You can then access the vtctld web interface
at port 15000 of the IP address returned in the above command.
In this example, the web UI would be at
https://104.154.64.12:15000.
Use vtctlclient to call vtctld

You can now run vtctlclient locally to issue commands
to the vtctld service on your Kubernetes cluster.

When you call vtctlclient, the command includes
the IP address and port for your vtctld service.
To avoid having to enter that for each command, create an alias
called :
$ alias kvtctl=&#39;vtctlclient -server VTCTLD_IP_ADDRESS:15000&#39;

Now, running kvtctl will test your connection to
vtctld and also list the vtctlclient
commands that you can use to administer the Vitess cluster.
# Test the connection to vtctld and list available commands
$ kvtctl help
No command specified please see the list below:
Tablets:
InitTablet ...
...

Start vttablets

Call the following script to launch vttablet
and mysqld in a pod:
vitess/examples/kubernetes$ ./vttablet-up.sh
### Output from vttablet-up.sh is shown below
# Creating test_keyspace.shard-0 pods in cell test...
# Creating pod for tablet test-0000000100...
# vttablet-100
#
# Creating pod for tablet test-0000000101...
# vttablet-101
#
# Creating pod for tablet test-0000000102...
# vttablet-102

Wait until you see the tablets listed in the
DBTopology Tool summary page for your vtctld
instance. This can take some time if a pod was scheduled on a
minion that needs to download the latest Vitess Docker image.
You can also check the status of the tablets from the command
line using kvtctl.
$ kvtctl ListAllTablets test

By bringing up tablets in a previously empty keyspace, you
have effectively just created a new shard. To initialize the
keyspace for the new shard, call the
vtctl RebuildKeyspaceGraph command:
$ kvtctl RebuildKeyspaceGraph test_keyspace

After this command completes, go back to the vtctld
UI and click the DBTopology Tool link. You should see the
three tablets listed. If you click the address of a tablet, you
will see the coordination data stored in etcd.

Note: Most vtctlclient commands produce no
output on success.

Status pages for vttablets

Each vttablet serves a set of HTML status pages
on its primary port. The vtctld interface provides
a link to the status page for each tablet, but the links are
actually to internal, per-pod IPs that can only be accessed
from within Kubernetes.

As such, if you try to connect to one of the [status]
links, you will get a 502 HTTP response.

As a workaround, you can proxy over an SSH connection to a
Kubernetes minion, or you can launch a proxy as a Kubernetes
service. In the future, we plan to provide proxying via the
Kubernetes API server without a need for additional setup.
Elect a master vttablet

The vttablets are all started as replicas. In this step, you
designate one of the vttablets to be the master. Vitess
automatically connects the other replicas&#39; mysqld instances
so that they start replicating from the master&#39;s mysqld.

Since this is the first time the shard has been started,
the vttablets are not already doing any replication. As a
result, the following command uses the -force
flag when calling the ReparentShard command
to skip the usual validation of each tablet&#39;s replication state.
$ kvtctl ReparentShard -force test_keyspace/0 test-0000000100

Note: If you do not include the -force flag
here, the command will first check to ensure that slave databases
are replicating correctly. However, since the slaves aren&#39;t
replicating at all, that check would fail and the command
would fail as well.

After running this command, go back to the DBTopology Tool
in the vtctld web interface. When you refresh the
page, you should see that one vttablet is the master
and the other two are replicas.

You can also run this command on the command line to see the
same data:
$ kvtctl ListAllTablets test

Create a table

The vtctlclient tool implements the database schema
across all tablets in a keyspace. The following command creates
the table defined in the createtesttable.sql file:
vitess/examples/kubernetes$ kvtctl ApplySchemaKeyspace -simple -sql &quot;$(cat create_test_table.sql)&quot; test_keyspace

The SQL to create the table is shown below:
CREATE TABLE test_table (
id BIGINT AUTO_INCREMENT,
msg VARCHAR(250),
PRIMARY KEY(id)
) Engine=InnoDB

You can run this command to confirm that the schema was created
properly on a given tablet, where test-0000000100
is a tablet ID as listed in step 4 or step 7:
kvtctl GetSchema test-0000000100
# The command&#39;s output is shown below:
# test-0000000100 test_keyspace 0 master MASTER_IP:15002 MASTER_IP:3306 []
# test-0000000101 test_keyspace 0 replica REPLICA_IP:15002 REPLICA_IP:3306 []
# test-0000000102 test_keyspace 0 replica REPLICA_IP:15002 REPLICA_IP:3306 []

Start vtgate

Vitess uses vtgate to route each client query
to the correct vttablet. In Kubernetes, a
vtgate service distributes connections to a pool
of vtgate pods. The pods are curated by a replication
controller.
vitess/examples/kubernetes$ ./vtgate-up.sh



Test your instance with a client app

The GuestBook app in the example is ported from the Kubernetes GuestBook example. The server-side code has been rewritten in Python to use Vitess as the storage engine. The client-side code (HTML/JavaScript) is essentially unchanged.
vitess/examples/kubernetes$ ./guestbook-up.sh

As with the vtctld service, to access the GuestBook
app from outside Kubernetes, you need to open a port (3000) on
your firewall.
# Open port 3000 in the firewall
$ gcloud compute firewall-rules create guestbook --allow tcp:3000

Then, get the external IP of the load balancer for the GuestBook service:
$ gcloud compute forwarding-rules list
NAME      REGION      IP_ADDRESS     IP_PROTOCOL TARGET
guestbook us-central1 146.148.72.125 TCP         us-central1/targetPools/guestbook
vtctld    us-central1 104.154.64.12  TCP         us-central1/targetPools/vtctld

Once the pods are running, the GuestBook app should be accessible
from port 3000 on the external IP.

You can see Vitess&#39; replication capabilities by opening the app in
multiple browser windows. Each new entry is committed to the master
database. In the meantime, JavaScript on the page continuously polls
the app server to retrieve a list of GuestBook entries. The app serves
read-only requests by querying Vitess in &#39;replica&#39; mode, confirming
that replication is working.

The GuestBook source code
provides more detail about how the app server interacts with Vitess.

Tear down and clean up

The following command tears down the Container Engine cluster. It is
necessary to stop the virtual machines running on the Cloud platform.
$ gcloud preview container clusters delete example

And these commands clean up other entities created for this example.
They are suggested to prevent conflicts that might occur if you
don&#39;t run them and then rerun this example in a different mode.
$ gcloud compute forwarding-rules delete vtctld
$ gcloud compute firewall-rules delete vtctld
$ gcloud compute target-pools delete vtctld

Troubleshooting

If a pod enters the Running state, but the server
doesn&#39;t respond as expected, use the kubectl log
command to check the pod output:
# show logs for container &#39;vttablet&#39; within pod &#39;vttablet-100&#39;
$ $KUBECTL log vttablet-100 vttablet

# show logs for container &#39;mysql&#39; within pod &#39;vttablet-100&#39;
$ $KUBECTL log vttablet-100 mysql

Post the logs somewhere and send a link to the Vitess
mailing list
to get more help.
">
    <meta name="keywords" content="">
    
    
    	<!-- Twitter Cards -->
	<meta name="twitter:title" content="GettingStartedKubernetes">
	<meta name="twitter:description" content="This page explains how to start a Kubernetes cluster and also run
Vitess on Kubernetes. This example was most recently tested using
the binary release of Kubernetes v0.9.1.

Prerequisites

To complete the exercise in this guide, you must locally install Go 1.3+,
Vitess&#39; vtctlclient tool, and Google Cloud SDK. The
following sections explain how to set these up in your environment.

Install Go 1.3+

You need to install Go 1.3+ to build the
vtctlclient tool, which issues commands to Vitess.

After installing Go, make sure your GOPATH environment
variable is set to the root of your workspace. The most common setting
is GOPATH=$HOME/go, and the value should identify a
directory to which your non-root user has write access.

In addition, make sure that $GOPATH/bin is included in
your $PATH. More information about setting up a Go
workspace can be found at
http://golang.org/doc/code.html#Organization.

Build and install vtctlclient

The vtctlclient tool issues commands to Vitess.
$ go get git￼￼hub.com/youtube/vitess/go/cmd/vtctlclient

This command downloads and builds the Vitess source code at:
$GOPATH/src/github.com/youtube/vitess/

It also copies the built vtctlclient binary into $GOPATH/bin.

Set up Google Compute Engine, Container Engine, and Cloud tools

To run Vitess on Kubernetes using Google Compute Engine (GCE),
you must have a GCE account with billing enabled. The instructions
below explain how to enable billing and how to associate a billing
account with a project in the Google Developers Console.


Log in to the Google Developers Console to enable billing.


 Click the Billing pane if you are not there already.
 Click New billing account
 Assign a name to the billing account -- e.g. &quot;Vitess on
Kubernetes.&quot; Then click Continue. You can sign up
for the free trial
to avoid any charges.

Create a project in the Google Developers Console that uses
your billing account:


 In the Google Developers Console, click the Projects pane.
 Click the Create Project button.
 Assign a name to your project. Then click the Create button.
Your project should be created and associated with your
billing account. (If you have multiple billing accounts,
confirm that the project is associated with the correct account.)
 After creating your project, click APIs &amp; auth in the left menu.
 Click APIs.
 Find Google Compute Engine and Google Container Engine API
and click the OFF button for each to enable those two APIs.

Follow the GCE quickstart guide to set up
and test the Google Cloud SDK. You will also set your default project
ID while completing the quickstart. Start with step 2 in the setup
process.

Note: During the quickstart, you&#39;ll generate an SSH key for
Google Compute Engine, and you will be prompted to enter a
passphrase. You will be prompted for that passphrase several times
when bringing up your Kubernetes cluster later in this guide.


Start a Kubernetes cluster


Set the KUBECTL environment variable to point to the
gcloud command:
$ export KUBECTL=&#39;gcloud preview container kubectl&#39;

Enable preview features in the gcloud tool:
$ gcloud components update preview

If you did not complete the GCE quickstart guide, set
your default project ID by running the following command.
Replace PROJECT with the project ID assigned to your
Google Developers Console
project. You can find the ID
by navigating to the Overview page for the project
in the Console.
$ gcloud config set project PROJECT

Set the zone
that your installation will use:
$ gcloud config set compute/zone us-central1-b

Create a Kubernetes cluster:
$ gcloud preview container clusters create example --machine-type n1-standard-1 --num-nodes 3

While the cluster is starting, you will be prompted several
times for the passphrase you created while setting up Google
Compute Engine.
The command&#39;s output includes the URL for the Kubernetes master server:
endpoint: 146.148.70.28
masterAuth:
password: YOUR_PASSWORD
user: admin


 Open the endpoint URL in a browser to get the full effect
of the &quot;Hello World&quot; experience in Kubernetes.
 If you see a ERRCERTAUTHORITY_INVALID error
indicating that the server&#39;s security certificate is not
trusted by your computer&#39;s operating system, click the
Advanced link and then the link to proceed to the URL.
 You should be prompted to enter a username and password to
access the requested page. Enter the masterAuth
username and password from the gcloud command&#39;s
output.



Start a Vitess cluster


Navigate to your local Vitess source code

This directory would have been created when you installed
vtctlclient:
$ cd $GOPATH/src/github.com/youtube/vitess

Start an etcd cluster:
$ cd examples/kubernetes
vitess/examples/kubernetes$ ./etcd-up.sh

This command creates two clusters. One is for the global cell,
and the other is for the test cell. You can check the status
of the pods
in the cluster by running:
$KUBECTL get pods

It may take a while for each Kubernetes minion to download the
Docker images the first time it needs them. While the images
are downloading, the pod status will be Pending.

Note: In this example, each script that has a name ending in
-up.sh also has a corresponding -down.sh
script, which can be used to stop certain components of the
Vitess cluster without bringing down the whole cluster. For
example, to tear down the etcd deployment, run:
vitess/examples/kubernetes$ ./etcd-down.sh

Start vtctld

The vtctld server provides a web interface to
inspect the state of the Vitess cluster. It also accepts RPC
commands from vtctlclient to modify the cluster.
vitess/examples/kubernetes$ ./vtctld-up.sh

To let you access vtctld from outside Kubernetes,
the vtctld service is created with the
createExternalLoadBalancer option. This is a
convenient shortcut
for cloud providers that support external load balancers.
On supported platforms, Kubernetes will then automatically
create an external IP that load balances onto the pods
comprising the service.
Access vtctld

To access the vtctld service from outside
Kubernetes, you need to open port 15000 on the GCE firewall.
(If you don&#39;t complete this step, the only way to issue commands
to vtctld would be to SSH into a Kubernetes node
and install and run vtctlclient there.)
$ gcloud compute firewall-rules create vtctld --allow tcp:15000

Then, get the address of the load balancer for vtctld:
$ gcloud compute forwarding-rules list
NAME   REGION      IP_ADDRESS    IP_PROTOCOL TARGET
vtctld us-central1 104.154.64.12 TCP         us-central1/targetPools/vtctld

You can then access the vtctld web interface
at port 15000 of the IP address returned in the above command.
In this example, the web UI would be at
https://104.154.64.12:15000.
Use vtctlclient to call vtctld

You can now run vtctlclient locally to issue commands
to the vtctld service on your Kubernetes cluster.

When you call vtctlclient, the command includes
the IP address and port for your vtctld service.
To avoid having to enter that for each command, create an alias
called :
$ alias kvtctl=&#39;vtctlclient -server VTCTLD_IP_ADDRESS:15000&#39;

Now, running kvtctl will test your connection to
vtctld and also list the vtctlclient
commands that you can use to administer the Vitess cluster.
# Test the connection to vtctld and list available commands
$ kvtctl help
No command specified please see the list below:
Tablets:
InitTablet ...
...

Start vttablets

Call the following script to launch vttablet
and mysqld in a pod:
vitess/examples/kubernetes$ ./vttablet-up.sh
### Output from vttablet-up.sh is shown below
# Creating test_keyspace.shard-0 pods in cell test...
# Creating pod for tablet test-0000000100...
# vttablet-100
#
# Creating pod for tablet test-0000000101...
# vttablet-101
#
# Creating pod for tablet test-0000000102...
# vttablet-102

Wait until you see the tablets listed in the
DBTopology Tool summary page for your vtctld
instance. This can take some time if a pod was scheduled on a
minion that needs to download the latest Vitess Docker image.
You can also check the status of the tablets from the command
line using kvtctl.
$ kvtctl ListAllTablets test

By bringing up tablets in a previously empty keyspace, you
have effectively just created a new shard. To initialize the
keyspace for the new shard, call the
vtctl RebuildKeyspaceGraph command:
$ kvtctl RebuildKeyspaceGraph test_keyspace

After this command completes, go back to the vtctld
UI and click the DBTopology Tool link. You should see the
three tablets listed. If you click the address of a tablet, you
will see the coordination data stored in etcd.

Note: Most vtctlclient commands produce no
output on success.

Status pages for vttablets

Each vttablet serves a set of HTML status pages
on its primary port. The vtctld interface provides
a link to the status page for each tablet, but the links are
actually to internal, per-pod IPs that can only be accessed
from within Kubernetes.

As such, if you try to connect to one of the [status]
links, you will get a 502 HTTP response.

As a workaround, you can proxy over an SSH connection to a
Kubernetes minion, or you can launch a proxy as a Kubernetes
service. In the future, we plan to provide proxying via the
Kubernetes API server without a need for additional setup.
Elect a master vttablet

The vttablets are all started as replicas. In this step, you
designate one of the vttablets to be the master. Vitess
automatically connects the other replicas&#39; mysqld instances
so that they start replicating from the master&#39;s mysqld.

Since this is the first time the shard has been started,
the vttablets are not already doing any replication. As a
result, the following command uses the -force
flag when calling the ReparentShard command
to skip the usual validation of each tablet&#39;s replication state.
$ kvtctl ReparentShard -force test_keyspace/0 test-0000000100

Note: If you do not include the -force flag
here, the command will first check to ensure that slave databases
are replicating correctly. However, since the slaves aren&#39;t
replicating at all, that check would fail and the command
would fail as well.

After running this command, go back to the DBTopology Tool
in the vtctld web interface. When you refresh the
page, you should see that one vttablet is the master
and the other two are replicas.

You can also run this command on the command line to see the
same data:
$ kvtctl ListAllTablets test

Create a table

The vtctlclient tool implements the database schema
across all tablets in a keyspace. The following command creates
the table defined in the createtesttable.sql file:
vitess/examples/kubernetes$ kvtctl ApplySchemaKeyspace -simple -sql &quot;$(cat create_test_table.sql)&quot; test_keyspace

The SQL to create the table is shown below:
CREATE TABLE test_table (
id BIGINT AUTO_INCREMENT,
msg VARCHAR(250),
PRIMARY KEY(id)
) Engine=InnoDB

You can run this command to confirm that the schema was created
properly on a given tablet, where test-0000000100
is a tablet ID as listed in step 4 or step 7:
kvtctl GetSchema test-0000000100
# The command&#39;s output is shown below:
# test-0000000100 test_keyspace 0 master MASTER_IP:15002 MASTER_IP:3306 []
# test-0000000101 test_keyspace 0 replica REPLICA_IP:15002 REPLICA_IP:3306 []
# test-0000000102 test_keyspace 0 replica REPLICA_IP:15002 REPLICA_IP:3306 []

Start vtgate

Vitess uses vtgate to route each client query
to the correct vttablet. In Kubernetes, a
vtgate service distributes connections to a pool
of vtgate pods. The pods are curated by a replication
controller.
vitess/examples/kubernetes$ ./vtgate-up.sh



Test your instance with a client app

The GuestBook app in the example is ported from the Kubernetes GuestBook example. The server-side code has been rewritten in Python to use Vitess as the storage engine. The client-side code (HTML/JavaScript) is essentially unchanged.
vitess/examples/kubernetes$ ./guestbook-up.sh

As with the vtctld service, to access the GuestBook
app from outside Kubernetes, you need to open a port (3000) on
your firewall.
# Open port 3000 in the firewall
$ gcloud compute firewall-rules create guestbook --allow tcp:3000

Then, get the external IP of the load balancer for the GuestBook service:
$ gcloud compute forwarding-rules list
NAME      REGION      IP_ADDRESS     IP_PROTOCOL TARGET
guestbook us-central1 146.148.72.125 TCP         us-central1/targetPools/guestbook
vtctld    us-central1 104.154.64.12  TCP         us-central1/targetPools/vtctld

Once the pods are running, the GuestBook app should be accessible
from port 3000 on the external IP.

You can see Vitess&#39; replication capabilities by opening the app in
multiple browser windows. Each new entry is committed to the master
database. In the meantime, JavaScript on the page continuously polls
the app server to retrieve a list of GuestBook entries. The app serves
read-only requests by querying Vitess in &#39;replica&#39; mode, confirming
that replication is working.

The GuestBook source code
provides more detail about how the app server interacts with Vitess.

Tear down and clean up

The following command tears down the Container Engine cluster. It is
necessary to stop the virtual machines running on the Cloud platform.
$ gcloud preview container clusters delete example

And these commands clean up other entities created for this example.
They are suggested to prevent conflicts that might occur if you
don&#39;t run them and then rerun this example in a different mode.
$ gcloud compute forwarding-rules delete vtctld
$ gcloud compute firewall-rules delete vtctld
$ gcloud compute target-pools delete vtctld

Troubleshooting

If a pod enters the Running state, but the server
doesn&#39;t respond as expected, use the kubectl log
command to check the pod output:
# show logs for container &#39;vttablet&#39; within pod &#39;vttablet-100&#39;
$ $KUBECTL log vttablet-100 vttablet

# show logs for container &#39;mysql&#39; within pod &#39;vttablet-100&#39;
$ $KUBECTL log vttablet-100 mysql

Post the logs somewhere and send a link to the Vitess
mailing list
to get more help.
">
	
	
	
	<meta name="twitter:card" content="summary">
	<meta name="twitter:image" content="http://vitess.io/images/120x120.gif">
	
	<!-- Open Graph -->
	<meta property="og:locale" content="en_US">
	<meta property="og:type" content="article">
	<meta property="og:title" content="GettingStartedKubernetes">
	<meta property="og:description" content="This page explains how to start a Kubernetes cluster and also run
Vitess on Kubernetes. This example was most recently tested using
the binary release of Kubernetes v0.9.1.

Prerequisites

To complete the exercise in this guide, you must locally install Go 1.3+,
Vitess&#39; vtctlclient tool, and Google Cloud SDK. The
following sections explain how to set these up in your environment.

Install Go 1.3+

You need to install Go 1.3+ to build the
vtctlclient tool, which issues commands to Vitess.

After installing Go, make sure your GOPATH environment
variable is set to the root of your workspace. The most common setting
is GOPATH=$HOME/go, and the value should identify a
directory to which your non-root user has write access.

In addition, make sure that $GOPATH/bin is included in
your $PATH. More information about setting up a Go
workspace can be found at
http://golang.org/doc/code.html#Organization.

Build and install vtctlclient

The vtctlclient tool issues commands to Vitess.
$ go get git￼￼hub.com/youtube/vitess/go/cmd/vtctlclient

This command downloads and builds the Vitess source code at:
$GOPATH/src/github.com/youtube/vitess/

It also copies the built vtctlclient binary into $GOPATH/bin.

Set up Google Compute Engine, Container Engine, and Cloud tools

To run Vitess on Kubernetes using Google Compute Engine (GCE),
you must have a GCE account with billing enabled. The instructions
below explain how to enable billing and how to associate a billing
account with a project in the Google Developers Console.


Log in to the Google Developers Console to enable billing.


 Click the Billing pane if you are not there already.
 Click New billing account
 Assign a name to the billing account -- e.g. &quot;Vitess on
Kubernetes.&quot; Then click Continue. You can sign up
for the free trial
to avoid any charges.

Create a project in the Google Developers Console that uses
your billing account:


 In the Google Developers Console, click the Projects pane.
 Click the Create Project button.
 Assign a name to your project. Then click the Create button.
Your project should be created and associated with your
billing account. (If you have multiple billing accounts,
confirm that the project is associated with the correct account.)
 After creating your project, click APIs &amp; auth in the left menu.
 Click APIs.
 Find Google Compute Engine and Google Container Engine API
and click the OFF button for each to enable those two APIs.

Follow the GCE quickstart guide to set up
and test the Google Cloud SDK. You will also set your default project
ID while completing the quickstart. Start with step 2 in the setup
process.

Note: During the quickstart, you&#39;ll generate an SSH key for
Google Compute Engine, and you will be prompted to enter a
passphrase. You will be prompted for that passphrase several times
when bringing up your Kubernetes cluster later in this guide.


Start a Kubernetes cluster


Set the KUBECTL environment variable to point to the
gcloud command:
$ export KUBECTL=&#39;gcloud preview container kubectl&#39;

Enable preview features in the gcloud tool:
$ gcloud components update preview

If you did not complete the GCE quickstart guide, set
your default project ID by running the following command.
Replace PROJECT with the project ID assigned to your
Google Developers Console
project. You can find the ID
by navigating to the Overview page for the project
in the Console.
$ gcloud config set project PROJECT

Set the zone
that your installation will use:
$ gcloud config set compute/zone us-central1-b

Create a Kubernetes cluster:
$ gcloud preview container clusters create example --machine-type n1-standard-1 --num-nodes 3

While the cluster is starting, you will be prompted several
times for the passphrase you created while setting up Google
Compute Engine.
The command&#39;s output includes the URL for the Kubernetes master server:
endpoint: 146.148.70.28
masterAuth:
password: YOUR_PASSWORD
user: admin


 Open the endpoint URL in a browser to get the full effect
of the &quot;Hello World&quot; experience in Kubernetes.
 If you see a ERRCERTAUTHORITY_INVALID error
indicating that the server&#39;s security certificate is not
trusted by your computer&#39;s operating system, click the
Advanced link and then the link to proceed to the URL.
 You should be prompted to enter a username and password to
access the requested page. Enter the masterAuth
username and password from the gcloud command&#39;s
output.



Start a Vitess cluster


Navigate to your local Vitess source code

This directory would have been created when you installed
vtctlclient:
$ cd $GOPATH/src/github.com/youtube/vitess

Start an etcd cluster:
$ cd examples/kubernetes
vitess/examples/kubernetes$ ./etcd-up.sh

This command creates two clusters. One is for the global cell,
and the other is for the test cell. You can check the status
of the pods
in the cluster by running:
$KUBECTL get pods

It may take a while for each Kubernetes minion to download the
Docker images the first time it needs them. While the images
are downloading, the pod status will be Pending.

Note: In this example, each script that has a name ending in
-up.sh also has a corresponding -down.sh
script, which can be used to stop certain components of the
Vitess cluster without bringing down the whole cluster. For
example, to tear down the etcd deployment, run:
vitess/examples/kubernetes$ ./etcd-down.sh

Start vtctld

The vtctld server provides a web interface to
inspect the state of the Vitess cluster. It also accepts RPC
commands from vtctlclient to modify the cluster.
vitess/examples/kubernetes$ ./vtctld-up.sh

To let you access vtctld from outside Kubernetes,
the vtctld service is created with the
createExternalLoadBalancer option. This is a
convenient shortcut
for cloud providers that support external load balancers.
On supported platforms, Kubernetes will then automatically
create an external IP that load balances onto the pods
comprising the service.
Access vtctld

To access the vtctld service from outside
Kubernetes, you need to open port 15000 on the GCE firewall.
(If you don&#39;t complete this step, the only way to issue commands
to vtctld would be to SSH into a Kubernetes node
and install and run vtctlclient there.)
$ gcloud compute firewall-rules create vtctld --allow tcp:15000

Then, get the address of the load balancer for vtctld:
$ gcloud compute forwarding-rules list
NAME   REGION      IP_ADDRESS    IP_PROTOCOL TARGET
vtctld us-central1 104.154.64.12 TCP         us-central1/targetPools/vtctld

You can then access the vtctld web interface
at port 15000 of the IP address returned in the above command.
In this example, the web UI would be at
https://104.154.64.12:15000.
Use vtctlclient to call vtctld

You can now run vtctlclient locally to issue commands
to the vtctld service on your Kubernetes cluster.

When you call vtctlclient, the command includes
the IP address and port for your vtctld service.
To avoid having to enter that for each command, create an alias
called :
$ alias kvtctl=&#39;vtctlclient -server VTCTLD_IP_ADDRESS:15000&#39;

Now, running kvtctl will test your connection to
vtctld and also list the vtctlclient
commands that you can use to administer the Vitess cluster.
# Test the connection to vtctld and list available commands
$ kvtctl help
No command specified please see the list below:
Tablets:
InitTablet ...
...

Start vttablets

Call the following script to launch vttablet
and mysqld in a pod:
vitess/examples/kubernetes$ ./vttablet-up.sh
### Output from vttablet-up.sh is shown below
# Creating test_keyspace.shard-0 pods in cell test...
# Creating pod for tablet test-0000000100...
# vttablet-100
#
# Creating pod for tablet test-0000000101...
# vttablet-101
#
# Creating pod for tablet test-0000000102...
# vttablet-102

Wait until you see the tablets listed in the
DBTopology Tool summary page for your vtctld
instance. This can take some time if a pod was scheduled on a
minion that needs to download the latest Vitess Docker image.
You can also check the status of the tablets from the command
line using kvtctl.
$ kvtctl ListAllTablets test

By bringing up tablets in a previously empty keyspace, you
have effectively just created a new shard. To initialize the
keyspace for the new shard, call the
vtctl RebuildKeyspaceGraph command:
$ kvtctl RebuildKeyspaceGraph test_keyspace

After this command completes, go back to the vtctld
UI and click the DBTopology Tool link. You should see the
three tablets listed. If you click the address of a tablet, you
will see the coordination data stored in etcd.

Note: Most vtctlclient commands produce no
output on success.

Status pages for vttablets

Each vttablet serves a set of HTML status pages
on its primary port. The vtctld interface provides
a link to the status page for each tablet, but the links are
actually to internal, per-pod IPs that can only be accessed
from within Kubernetes.

As such, if you try to connect to one of the [status]
links, you will get a 502 HTTP response.

As a workaround, you can proxy over an SSH connection to a
Kubernetes minion, or you can launch a proxy as a Kubernetes
service. In the future, we plan to provide proxying via the
Kubernetes API server without a need for additional setup.
Elect a master vttablet

The vttablets are all started as replicas. In this step, you
designate one of the vttablets to be the master. Vitess
automatically connects the other replicas&#39; mysqld instances
so that they start replicating from the master&#39;s mysqld.

Since this is the first time the shard has been started,
the vttablets are not already doing any replication. As a
result, the following command uses the -force
flag when calling the ReparentShard command
to skip the usual validation of each tablet&#39;s replication state.
$ kvtctl ReparentShard -force test_keyspace/0 test-0000000100

Note: If you do not include the -force flag
here, the command will first check to ensure that slave databases
are replicating correctly. However, since the slaves aren&#39;t
replicating at all, that check would fail and the command
would fail as well.

After running this command, go back to the DBTopology Tool
in the vtctld web interface. When you refresh the
page, you should see that one vttablet is the master
and the other two are replicas.

You can also run this command on the command line to see the
same data:
$ kvtctl ListAllTablets test

Create a table

The vtctlclient tool implements the database schema
across all tablets in a keyspace. The following command creates
the table defined in the createtesttable.sql file:
vitess/examples/kubernetes$ kvtctl ApplySchemaKeyspace -simple -sql &quot;$(cat create_test_table.sql)&quot; test_keyspace

The SQL to create the table is shown below:
CREATE TABLE test_table (
id BIGINT AUTO_INCREMENT,
msg VARCHAR(250),
PRIMARY KEY(id)
) Engine=InnoDB

You can run this command to confirm that the schema was created
properly on a given tablet, where test-0000000100
is a tablet ID as listed in step 4 or step 7:
kvtctl GetSchema test-0000000100
# The command&#39;s output is shown below:
# test-0000000100 test_keyspace 0 master MASTER_IP:15002 MASTER_IP:3306 []
# test-0000000101 test_keyspace 0 replica REPLICA_IP:15002 REPLICA_IP:3306 []
# test-0000000102 test_keyspace 0 replica REPLICA_IP:15002 REPLICA_IP:3306 []

Start vtgate

Vitess uses vtgate to route each client query
to the correct vttablet. In Kubernetes, a
vtgate service distributes connections to a pool
of vtgate pods. The pods are curated by a replication
controller.
vitess/examples/kubernetes$ ./vtgate-up.sh



Test your instance with a client app

The GuestBook app in the example is ported from the Kubernetes GuestBook example. The server-side code has been rewritten in Python to use Vitess as the storage engine. The client-side code (HTML/JavaScript) is essentially unchanged.
vitess/examples/kubernetes$ ./guestbook-up.sh

As with the vtctld service, to access the GuestBook
app from outside Kubernetes, you need to open a port (3000) on
your firewall.
# Open port 3000 in the firewall
$ gcloud compute firewall-rules create guestbook --allow tcp:3000

Then, get the external IP of the load balancer for the GuestBook service:
$ gcloud compute forwarding-rules list
NAME      REGION      IP_ADDRESS     IP_PROTOCOL TARGET
guestbook us-central1 146.148.72.125 TCP         us-central1/targetPools/guestbook
vtctld    us-central1 104.154.64.12  TCP         us-central1/targetPools/vtctld

Once the pods are running, the GuestBook app should be accessible
from port 3000 on the external IP.

You can see Vitess&#39; replication capabilities by opening the app in
multiple browser windows. Each new entry is committed to the master
database. In the meantime, JavaScript on the page continuously polls
the app server to retrieve a list of GuestBook entries. The app serves
read-only requests by querying Vitess in &#39;replica&#39; mode, confirming
that replication is working.

The GuestBook source code
provides more detail about how the app server interacts with Vitess.

Tear down and clean up

The following command tears down the Container Engine cluster. It is
necessary to stop the virtual machines running on the Cloud platform.
$ gcloud preview container clusters delete example

And these commands clean up other entities created for this example.
They are suggested to prevent conflicts that might occur if you
don&#39;t run them and then rerun this example in a different mode.
$ gcloud compute forwarding-rules delete vtctld
$ gcloud compute firewall-rules delete vtctld
$ gcloud compute target-pools delete vtctld

Troubleshooting

If a pod enters the Running state, but the server
doesn&#39;t respond as expected, use the kubectl log
command to check the pod output:
# show logs for container &#39;vttablet&#39; within pod &#39;vttablet-100&#39;
$ $KUBECTL log vttablet-100 vttablet

# show logs for container &#39;mysql&#39; within pod &#39;vttablet-100&#39;
$ $KUBECTL log vttablet-100 mysql

Post the logs somewhere and send a link to the Vitess
mailing list
to get more help.
">
	<meta property="og:url" content="http://vitess.io/doc/GettingStartedKubernetes/">
	<meta property="og:site_name" content="Vitess">

    <link rel="canonical" href="http://vitess.io/doc/GettingStartedKubernetes/">

    <link href="http://vitess.io/sitemap.xml" type="application/xml" rel="sitemap" title="Sitemap">

    <meta name="HandheldFriendly" content="True">
    <meta name="MobileOptimized" content="320">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="cleartype" content="on">

    <style>
    .sliding-menu-content {
      top: 0;
      right: 0;
      text-align: center;
      visibility: hidden;
      height: 100%;
      width: 100%;
      -webkit-transform: translateX(100%);
      -moz-transform: translateX(100%);
      -ms-transform: translateX(100%);
      -o-transform: translateX(100%);
      transform: translateX(100%);
    }
    </style>

    <link rel="stylesheet" href="http://vitess.io/css/main.css">
    <!-- HTML5 Shiv and Media Query Support for IE -->
    <!--[if lt IE 9]>
      <script src="http://vitess.io/js/vendor/html5shiv.min.js"></script>
      <script src="http://vitess.io/js/vendor/respond.min.js"></script>
    <![endif]-->

  </head>

  <body>
    <header id="masthead">
  <div class="inner-wrap">
    <a href="http://vitess.io/" class="site-title">Vitess</a>
    <nav role="navigation" class="menu top-menu">
        <ul class="menu-item">
	<li class="home"><a href="/">Vitess</a></li>
	
    
        
    
    <li><a href="http://vitess.io/getting-started/" >Getting Started</a></li>
  
    
        
    
    <li><a href="http://vitess.io/doc/" >Documentation</a></li>
  
    
        
    
    <li><a href="http://vitess.io/about/" >About</a></li>
  
    
        
    
    <li><a href="http://vitess.io/faq/" >FAQ</a></li>
  
</ul>
    </nav>
  </div>
</header>

    <nav role="navigation" class="js-menu sliding-menu-content">
	<ul class="menu-item">
		<li>
      
        
      
			<a href="http://vitess.io/getting-started/"><img src="http://vitess.io/images/400x250.gif" alt="teaser" class="teaser"></a>
			<a href="http://vitess.io/getting-started/" class="title">Getting Started</a>
			<p class="excerpt">Everything you need to know to get started with Vitess.</p>
		</li><li>
      
        
      
			<a href="http://vitess.io/doc/"><img src="http://vitess.io/images/400x250.gif" alt="teaser" class="teaser"></a>
			<a href="http://vitess.io/doc/" class="title">Documentation</a>
			<p class="excerpt">Vitess Docs.</p>
		</li><li>
      
        
      
			<a href="http://vitess.io/about/"><img src="http://vitess.io/images/400x250.gif" alt="teaser" class="teaser"></a>
			<a href="http://vitess.io/about/" class="title">About</a>
			<p class="excerpt">All about Vitess.</p>
		</li><li>
      
        
      
			<a href="http://vitess.io/faq/"><img src="http://vitess.io/images/400x250.gif" alt="teaser" class="teaser"></a>
			<a href="http://vitess.io/faq/" class="title">FAQ</a>
			<p class="excerpt">Vitess Faq.</p>
		</li>
	</ul>
</nav>
<button type="button" class="js-menu-trigger sliding-menu-button menulines-button x2" role="button" aria-label="Toggle Navigation">
	<span class="menulines"></span>
</button>

<div class="js-menu-screen menu-screen"></div>

    <div id="page-wrapper">
      <!--[if lt IE 9]><div class="upgrade notice-danger"><strong>Your browser is quite old!</strong> Why not <a href="http://whatbrowser.org/">upgrade to a newer one</a> to better enjoy this site?</div><![endif]-->

      <div id="main" role="main">
  <article class="wrap" itemscope itemtype="http://schema.org/Article">
    
    
  <nav class="breadcrumbs">
    <span itemscope itemtype="http://data-vocabulary.org/Breadcrumb">
      <a href="http://vitess.io" itemprop="url">
        <span itemprop="title">Home</span>
      </a> › 
    <span itemscope itemtype="http://data-vocabulary.org/Breadcrumb">
      <a href="http://vitess.io/doc/" itemprop="url">
        <span itemprop="title">Doc</span>
      </a>
    </span>
  </nav>


    <div class="inner-wrap">
      <nav class="toc"></nav>
      <div id="content" class="page-content" itemprop="articleBody">
	<p>This page explains how to start a Kubernetes cluster and also run
Vitess on Kubernetes. This example was most recently tested using
the binary release of Kubernetes v0.9.1.</p>

<h2 id="prerequisites">Prerequisites</h2>

<p>To complete the exercise in this guide, you must locally install Go 1.3+,
Vitess&#39; <code>vtctlclient</code> tool, and Google Cloud SDK. The
following sections explain how to set these up in your environment.</p>

<h3 id="install-go-1.3+">Install Go 1.3+</h3>

<p>You need to install <a href="http://golang.org/doc/install">Go 1.3+</a> to build the
<code>vtctlclient</code> tool, which issues commands to Vitess.</p>

<p>After installing Go, make sure your <code>GOPATH</code> environment
variable is set to the root of your workspace. The most common setting
is <code>GOPATH=$HOME/go</code>, and the value should identify a
directory to which your non-root user has write access.</p>

<p>In addition, make sure that <code>$GOPATH/bin</code> is included in
your <code>$PATH</code>. More information about setting up a Go
workspace can be found at
<a href="http://golang.org/doc/code.html#Organization">http://golang.org/doc/code.html#Organization</a>.</p>

<h2 id="build-and-install-vtctlclient">Build and install <code>vtctlclient</code></h2>

<p>The <code>vtctlclient</code> tool issues commands to Vitess.</p>
<div class="highlight"><pre><code class="language-sh" data-lang="sh"><span class="nv">$ </span>go get git￼￼hub.com/youtube/vitess/go/cmd/vtctlclient
</code></pre></div>
<p>This command downloads and builds the Vitess source code at:</p>
<div class="highlight"><pre><code class="language-sh" data-lang="sh"><span class="nv">$GOPATH</span>/src/github.com/youtube/vitess/
</code></pre></div>
<p>It also copies the built <code>vtctlclient</code> binary into <code>$GOPATH/bin</code>.</p>

<h3 id="set-up-google-compute-engine,-container-engine,-and-cloud-tools">Set up Google Compute Engine, Container Engine, and Cloud tools</h3>

<p>To run Vitess on Kubernetes using Google Compute Engine (GCE),
you must have a GCE account with billing enabled. The instructions
below explain how to enable billing and how to associate a billing
account with a project in the Google Developers Console.</p>

<ol>
<li><p>Log in to the Google Developers Console to <a href="https://console.developers.google.com/billing">enable billing</a>.</p>

<ol>
<li> Click the <strong>Billing</strong> pane if you are not there already.</li>
<li> Click <strong>New billing account</strong></li>
<li> Assign a name to the billing account -- e.g. &quot;Vitess on
Kubernetes.&quot; Then click <strong>Continue</strong>. You can sign up
for the <a href="https://cloud.google.com/free-trial/">free trial</a>
to avoid any charges.</li>
</ol></li>
<li><p>Create a project in the Google Developers Console that uses
your billing account:</p>

<ol>
<li> In the Google Developers Console, click the <strong>Projects</strong> pane.</li>
<li> Click the Create Project button.</li>
<li> Assign a name to your project. Then click the <strong>Create</strong> button.
Your project should be created and associated with your
billing account. (If you have multiple billing accounts,
confirm that the project is associated with the correct account.)</li>
<li> After creating your project, click <strong>APIs &amp; auth</strong> in the left menu.</li>
<li> Click <strong>APIs</strong>.</li>
<li> Find <strong>Google Compute Engine</strong> and <strong>Google Container Engine API</strong>
and click the <strong>OFF</strong> button for each to enable those two APIs.</li>
</ol></li>
<li><p>Follow the <a href="https://cloud.google.com/compute/docs/quickstart#setup">GCE quickstart guide</a> to set up
and test the Google Cloud SDK. You will also set your default project
ID while completing the quickstart. Start with step 2 in the setup
process.</p>

<p><strong>Note:</strong> During the quickstart, you&#39;ll generate an SSH key for
Google Compute Engine, and you will be prompted to enter a
passphrase. You will be prompted for that passphrase several times
when bringing up your Kubernetes cluster later in this guide.</p></li>
</ol>

<h2 id="start-a-kubernetes-cluster">Start a Kubernetes cluster</h2>

<ol>
<li><p>Set the <code>KUBECTL</code> environment variable to point to the
<code>gcloud</code> command:</p>
<div class="highlight"><pre><code class="language-sh" data-lang="sh"><span class="nv">$ </span><span class="nb">export </span><span class="nv">KUBECTL</span><span class="o">=</span><span class="s1">&#39;gcloud preview container kubectl&#39;</span>
</code></pre></div></li>
<li><p>Enable preview features in the <code>gcloud</code> tool:</p>
<div class="highlight"><pre><code class="language-sh" data-lang="sh"><span class="nv">$ </span>gcloud components update preview
</code></pre></div></li>
<li><p>If you did not complete the <a href="https://cloud.google.com/compute/docs/quickstart#setup">GCE quickstart guide</a>, set
your default project ID by running the following command.
Replace <code>PROJECT</code> with the project ID assigned to your
<a href="https://console.developers.google.com/">Google Developers Console</a>
project. You can <a href="https://cloud.google.com/compute/docs/overview#projectids">find the ID</a>
by navigating to the <strong>Overview</strong> page for the project
in the Console.</p>
<div class="highlight"><pre><code class="language-sh" data-lang="sh"><span class="nv">$ </span>gcloud config <span class="nb">set </span>project PROJECT
</code></pre></div></li>
<li><p>Set the <a href="https://cloud.google.com/compute/docs/zones#overview">zone</a>
that your installation will use:</p>
<div class="highlight"><pre><code class="language-sh" data-lang="sh"><span class="nv">$ </span>gcloud config <span class="nb">set </span>compute/zone us-central1-b
</code></pre></div></li>
<li><p>Create a Kubernetes cluster:</p>
<div class="highlight"><pre><code class="language-sh" data-lang="sh"><span class="nv">$ </span>gcloud preview container clusters create example --machine-type n1-standard-1 --num-nodes 3
</code></pre></div></li>
<li><p>While the cluster is starting, you will be prompted several
times for the passphrase you created while setting up Google
Compute Engine.</p></li>
<li><p>The command&#39;s output includes the URL for the Kubernetes master server:</p>
<div class="highlight"><pre><code class="language-sh" data-lang="sh">endpoint: 146.148.70.28
masterAuth:
password: YOUR_PASSWORD
user: admin
</code></pre></div>
<ol>
<li> Open the endpoint URL in a browser to get the full effect
of the &quot;Hello World&quot; experience in Kubernetes.</li>
<li> If you see a <code>ERRCERTAUTHORITY_INVALID</code> error
indicating that the server&#39;s security certificate is not
trusted by your computer&#39;s operating system, click the
<strong>Advanced</strong> link and then the link to proceed to the URL.</li>
<li> You should be prompted to enter a username and password to
access the requested page. Enter the <code>masterAuth</code>
username and password from the <code>gcloud</code> command&#39;s
output.</li>
</ol></li>
</ol>

<h2 id="start-a-vitess-cluster">Start a Vitess cluster</h2>

<ol>
<li><p><strong>Navigate to your local Vitess source code</strong></p>

<p>This directory would have been created when you installed
<code>vtctlclient</code>:</p>
<div class="highlight"><pre><code class="language-sh" data-lang="sh"><span class="nv">$ </span><span class="nb">cd</span> <span class="nv">$GOPATH</span>/src/github.com/youtube/vitess
</code></pre></div></li>
<li><p><strong>Start an etcd cluster:</strong></p>
<div class="highlight"><pre><code class="language-sh" data-lang="sh"><span class="nv">$ </span><span class="nb">cd </span>examples/kubernetes
vitess/examples/kubernetes<span class="nv">$ </span>./etcd-up.sh
</code></pre></div>
<p><br>This command creates two clusters. One is for the global cell,
and the other is for the test cell. You can check the status
of the <a href="https://github.com/GoogleCloudPlatform/kubernetes/blob/master/docs/pods.md">pods</a>
in the cluster by running:</p>
<div class="highlight"><pre><code class="language-sh" data-lang="sh"><span class="nv">$KUBECTL</span> get pods
</code></pre></div>
<p><br>It may take a while for each Kubernetes minion to download the
Docker images the first time it needs them. While the images
are downloading, the pod status will be Pending.<br><br></p>

<p><strong>Note:</strong> In this example, each script that has a name ending in
<code>-up.sh</code> also has a corresponding <code>-down.sh</code>
script, which can be used to stop certain components of the
Vitess cluster without bringing down the whole cluster. For
example, to tear down the <code>etcd</code> deployment, run:</p>
<div class="highlight"><pre><code class="language-sh" data-lang="sh">vitess/examples/kubernetes<span class="nv">$ </span>./etcd-down.sh
</code></pre></div></li>
<li><p><strong>Start vtctld</strong></p>

<p>The <code>vtctld</code> server provides a web interface to
inspect the state of the Vitess cluster. It also accepts RPC
commands from <code>vtctlclient</code> to modify the cluster.</p>
<div class="highlight"><pre><code class="language-sh" data-lang="sh">vitess/examples/kubernetes<span class="nv">$ </span>./vtctld-up.sh
</code></pre></div>
<p><br>To let you access <code>vtctld</code> from outside Kubernetes,
the <code>vtctld</code> service is created with the
<code>createExternalLoadBalancer</code> option. This is a
<a href="https://github.com/GoogleCloudPlatform/kubernetes/blob/master/docs/services.md#external-services">convenient shortcut</a>
for cloud providers that support external load balancers.
On supported platforms, Kubernetes will then automatically
create an external IP that load balances onto the pods
comprising the service.<br><br></p></li>
<li><p><strong>Access vtctld</strong></p>

<p>To access the <code>vtctld</code> service from outside
Kubernetes, you need to open port 15000 on the GCE firewall.
(If you don&#39;t complete this step, the only way to issue commands
to <code>vtctld</code> would be to SSH into a Kubernetes node
and install and run <code>vtctlclient</code> there.)</p>
<div class="highlight"><pre><code class="language-sh" data-lang="sh"><span class="nv">$ </span>gcloud compute firewall-rules create vtctld --allow tcp:15000
</code></pre></div>
<p><br>Then, get the address of the load balancer for <code>vtctld</code>:</p>
<div class="highlight"><pre><code class="language-sh" data-lang="sh"><span class="nv">$ </span>gcloud compute forwarding-rules list
NAME   REGION      IP_ADDRESS    IP_PROTOCOL TARGET
vtctld us-central1 104.154.64.12 TCP         us-central1/targetPools/vtctld
</code></pre></div>
<p><br>You can then access the <code>vtctld</code> web interface
at port 15000 of the IP address returned in the above command.
In this example, the web UI would be at
<code><a href="https://104.154.64.12:15000">https://104.154.64.12:15000</a></code>.</p></li>
<li><p><strong>Use <code>vtctlclient</code> to call <code>vtctld</code></strong></p>

<p>You can now run <code>vtctlclient</code> locally to issue commands
to the <code>vtctld</code> service on your Kubernetes cluster.<br><br></p>

<p>When you call <code>vtctlclient</code>, the command includes
the IP address and port for your <code>vtctld</code> service.
To avoid having to enter that for each command, create an alias
called <codekvtctl</code>:</p>
<div class="highlight"><pre><code class="language-sh" data-lang="sh"><span class="nv">$ </span><span class="nb">alias </span><span class="nv">kvtctl</span><span class="o">=</span><span class="s1">&#39;vtctlclient -server VTCTLD_IP_ADDRESS:15000&#39;</span>
</code></pre></div>
<p><br>Now, running <code>kvtctl</code> will test your connection to
<code>vtctld</code> and also list the <code>vtctlclient</code>
commands that you can use to administer the Vitess cluster.</p>
<div class="highlight"><pre><code class="language-sh" data-lang="sh"><span class="c"># Test the connection to vtctld and list available commands</span>
<span class="nv">$ </span>kvtctl <span class="nb">help</span>
No <span class="nb">command </span>specified please see the list below:
Tablets:
InitTablet ...
...
</code></pre></div></li>
<li><p><strong>Start vttablets</strong></p>

<p>Call the following script to launch <code>vttablet</code>
and <code>mysqld</code> in a <a href="https://github.com/GoogleCloudPlatform/kubernetes/blob/master/docs/pods.md">pod</a>:</p>
<div class="highlight"><pre><code class="language-sh" data-lang="sh">vitess/examples/kubernetes<span class="nv">$ </span>./vttablet-up.sh
<span class="c">### Output from vttablet-up.sh is shown below</span>
<span class="c"># Creating test_keyspace.shard-0 pods in cell test...</span>
<span class="c"># Creating pod for tablet test-0000000100...</span>
<span class="c"># vttablet-100</span>
<span class="c">#</span>
<span class="c"># Creating pod for tablet test-0000000101...</span>
<span class="c"># vttablet-101</span>
<span class="c">#</span>
<span class="c"># Creating pod for tablet test-0000000102...</span>
<span class="c"># vttablet-102</span>
</code></pre></div>
<p><br>Wait until you see the tablets listed in the
<strong>DBTopology Tool</strong> summary page for your <code>vtctld</code>
instance. This can take some time if a pod was scheduled on a
minion that needs to download the latest Vitess Docker image.
You can also check the status of the tablets from the command
line using <code>kvtctl</code>.</p>
<div class="highlight"><pre><code class="language-sh" data-lang="sh"><span class="nv">$ </span>kvtctl ListAllTablets <span class="nb">test</span>
</code></pre></div>
<p><br>By bringing up tablets in a previously empty keyspace, you
have effectively just created a new shard. To initialize the
keyspace for the new shard, call the
<code>vtctl RebuildKeyspaceGraph</code> command:</p>
<div class="highlight"><pre><code class="language-sh" data-lang="sh"><span class="nv">$ </span>kvtctl RebuildKeyspaceGraph test_keyspace
</code></pre></div>
<p><br>After this command completes, go back to the <code>vtctld</code>
UI and click the <strong>DBTopology Tool</strong> link. You should see the
three tablets listed. If you click the address of a tablet, you
will see the coordination data stored in <code>etcd</code>.<br><br></p>

<p><strong>Note:</strong> Most <code>vtctlclient</code> commands produce no
output on success.<br><br></p>

<p><strong><em>Status pages for vttablets</em></strong></p>

<p>Each <code>vttablet</code> serves a set of HTML status pages
on its primary port. The <code>vtctld</code> interface provides
a link to the status page for each tablet, but the links are
actually to internal, per-pod IPs that can only be accessed
from within Kubernetes.<br><br></p>

<p>As such, if you try to connect to one of the <strong>[status]</strong>
links, you will get a 502 HTTP response.<br><br></p>

<p>As a workaround, you can proxy over an SSH connection to a
Kubernetes minion, or you can launch a proxy as a Kubernetes
service. In the future, we plan to provide proxying via the
Kubernetes API server without a need for additional setup.</p></li>
<li><p><strong>Elect a master vttablet</strong></p>

<p>The vttablets are all started as replicas. In this step, you
designate one of the vttablets to be the master. Vitess
automatically connects the other replicas&#39; mysqld instances
so that they start replicating from the master&#39;s mysqld.<br><br></p>

<p>Since this is the first time the shard has been started,
the vttablets are not already doing any replication. As a
result, the following command uses the <code>-force</code>
flag when calling the <code>ReparentShard</code> command
to skip the usual validation of each tablet&#39;s replication state.</p>
<div class="highlight"><pre><code class="language-sh" data-lang="sh"><span class="nv">$ </span>kvtctl ReparentShard -force test_keyspace/0 <span class="nb">test</span>-0000000100
</code></pre></div>
<p><br><strong>Note:</strong> If you do not include the <code>-force</code> flag
here, the command will first check to ensure that slave databases
are replicating correctly. However, since the slaves aren&#39;t
replicating at all, that check would fail and the command
would fail as well.<br><br></p>

<p>After running this command, go back to the <strong>DBTopology Tool</strong>
in the <code>vtctld</code> web interface. When you refresh the
page, you should see that one <code>vttablet</code> is the master
and the other two are replicas.<br><br></p>

<p>You can also run this command on the command line to see the
same data:</p>
<div class="highlight"><pre><code class="language-sh" data-lang="sh"><span class="nv">$ </span>kvtctl ListAllTablets <span class="nb">test</span>
</code></pre></div></li>
<li><p><strong>Create a table</strong></p>

<p>The <code>vtctlclient</code> tool implements the database schema
across all tablets in a keyspace. The following command creates
the table defined in the <em>createtesttable.sql</em> file:</p>
<div class="highlight"><pre><code class="language-sh" data-lang="sh">vitess/examples/kubernetes<span class="nv">$ </span>kvtctl ApplySchemaKeyspace -simple -sql <span class="s2">&quot;$(cat create_test_table.sql)&quot;</span> test_keyspace
</code></pre></div>
<p><br>The SQL to create the table is shown below:</p>
<div class="highlight"><pre><code class="language-sh" data-lang="sh">CREATE TABLE test_table <span class="o">(</span>
id BIGINT AUTO_INCREMENT,
msg VARCHAR<span class="o">(</span>250<span class="o">)</span>,
PRIMARY KEY<span class="o">(</span>id<span class="o">)</span>
<span class="o">)</span> <span class="nv">Engine</span><span class="o">=</span>InnoDB
</code></pre></div>
<p><br>You can run this command to confirm that the schema was created
properly on a given tablet, where <code>test-0000000100</code>
is a tablet ID as listed in step 4 or step 7:</p>
<div class="highlight"><pre><code class="language-sh" data-lang="sh">kvtctl GetSchema <span class="nb">test</span>-0000000100
<span class="c"># The command&#39;s output is shown below:</span>
<span class="c"># test-0000000100 test_keyspace 0 master MASTER_IP:15002 MASTER_IP:3306 []</span>
<span class="c"># test-0000000101 test_keyspace 0 replica REPLICA_IP:15002 REPLICA_IP:3306 []</span>
<span class="c"># test-0000000102 test_keyspace 0 replica REPLICA_IP:15002 REPLICA_IP:3306 []</span>
</code></pre></div></li>
<li><p><strong>Start <code>vtgate</code></strong></p>

<p>Vitess uses <code>vtgate</code> to route each client query
to the correct <code>vttablet</code>. In Kubernetes, a
<code>vtgate</code> service distributes connections to a pool
of <code>vtgate</code> pods. The pods are curated by a <a href="https://github.com/GoogleCloudPlatform/kubernetes/blob/master/docs/replication-controller.md">replication
controller</a>.</p>
<div class="highlight"><pre><code class="language-sh" data-lang="sh">vitess/examples/kubernetes<span class="nv">$ </span>./vtgate-up.sh
</code></pre></div></li>
</ol>

<h2 id="test-your-instance-with-a-client-app">Test your instance with a client app</h2>

<p>The GuestBook app in the example is ported from the <a href="https://github.com/GoogleCloudPlatform/kubernetes/tree/master/examples/guestbook-go">Kubernetes GuestBook example</a>. The server-side code has been rewritten in Python to use Vitess as the storage engine. The client-side code (HTML/JavaScript) is essentially unchanged.</p>
<div class="highlight"><pre><code class="language-sh" data-lang="sh">vitess/examples/kubernetes<span class="nv">$ </span>./guestbook-up.sh
</code></pre></div>
<p>As with the <code>vtctld</code> service, to access the GuestBook
app from outside Kubernetes, you need to open a port (3000) on
your firewall.</p>
<div class="highlight"><pre><code class="language-sh" data-lang="sh"><span class="c"># Open port 3000 in the firewall</span>
<span class="nv">$ </span>gcloud compute firewall-rules create guestbook --allow tcp:3000
</code></pre></div>
<p>Then, get the external IP of the load balancer for the GuestBook service:</p>
<div class="highlight"><pre><code class="language-sh" data-lang="sh"><span class="nv">$ </span>gcloud compute forwarding-rules list
NAME      REGION      IP_ADDRESS     IP_PROTOCOL TARGET
guestbook us-central1 146.148.72.125 TCP         us-central1/targetPools/guestbook
vtctld    us-central1 104.154.64.12  TCP         us-central1/targetPools/vtctld
</code></pre></div>
<p>Once the pods are running, the GuestBook app should be accessible
from port 3000 on the external IP.</p>

<p>You can see Vitess&#39; replication capabilities by opening the app in
multiple browser windows. Each new entry is committed to the master
database. In the meantime, JavaScript on the page continuously polls
the app server to retrieve a list of GuestBook entries. The app serves
read-only requests by querying Vitess in &#39;replica&#39; mode, confirming
that replication is working.</p>

<p>The <a href="https://github.com/youtube/vitess/tree/master/examples/kubernetes/guestbook">GuestBook source code</a>
provides more detail about how the app server interacts with Vitess.</p>

<h2 id="tear-down-and-clean-up">Tear down and clean up</h2>

<p>The following command tears down the Container Engine cluster. It is
necessary to stop the virtual machines running on the Cloud platform.</p>
<div class="highlight"><pre><code class="language-sh" data-lang="sh"><span class="nv">$ </span>gcloud preview container clusters delete example
</code></pre></div>
<p>And these commands clean up other entities created for this example.
They are suggested to prevent conflicts that might occur if you
don&#39;t run them and then rerun this example in a different mode.</p>
<div class="highlight"><pre><code class="language-sh" data-lang="sh"><span class="nv">$ </span>gcloud compute forwarding-rules delete vtctld
<span class="nv">$ </span>gcloud compute firewall-rules delete vtctld
<span class="nv">$ </span>gcloud compute target-pools delete vtctld
</code></pre></div>
<h2 id="troubleshooting">Troubleshooting</h2>

<p>If a pod enters the <code>Running</code> state, but the server
doesn&#39;t respond as expected, use the <code>kubectl log</code>
command to check the pod output:</p>
<div class="highlight"><pre><code class="language-sh" data-lang="sh"><span class="c"># show logs for container &#39;vttablet&#39; within pod &#39;vttablet-100&#39;</span>
<span class="nv">$ $KUBECTL</span> log vttablet-100 vttablet

<span class="c"># show logs for container &#39;mysql&#39; within pod &#39;vttablet-100&#39;</span>
<span class="nv">$ $KUBECTL</span> log vttablet-100 mysql
</code></pre></div>
<p>Post the logs somewhere and send a link to the <a href="https://groups.google.com/forum/#!forum/vitess">Vitess
mailing list</a>
to get more help.</p>

	<hr />
	<footer class="page-footer">
	  


<div class="author-image">
	<img src="http://vitess.io/images/" alt="Vitess Team">
</div>
<div class="author-content">
	<h3 class="author-name" >Written by <a href="https://github.com/youtube/vitess" itemprop="author">Vitess Team</a></h3>
	<p class="author-bio"></p>
</div>

	  <div class="inline-btn">
	<a class="btn-social twitter" href="https://twitter.com/intent/tweet?text=GettingStartedKubernetes&amp;url=http://vitess.io/doc/GettingStartedKubernetes/&amp;via=" target="_blank"><i class="fa fa-twitter" aria-hidden="true"></i> Share on Twitter</a>
	<a class="btn-social facebook" href="https://www.facebook.com/sharer/sharer.php?u=http://vitess.io/doc/GettingStartedKubernetes/" target="_blank"><i class="fa fa-facebook" aria-hidden="true"></i> Share on Facebook</a>
	<a class="btn-social google-plus"  href="https://plus.google.com/share?url=http://vitess.io/doc/GettingStartedKubernetes/" target="_blank"><i class="fa fa-google-plus" aria-hidden="true"></i> Share on Google+</a>
</div>

	  <div class="page-meta">
	<p>Updated <time datetime="2015-01-01T00:00:00Z" itemprop="datePublished">January 01, 2015</time></p>
</div>

	</footer>
	<aside>
	  
	</aside>
      </div>
    </div>
  </article>
</div>


      <footer role="contentinfo" id="site-footer">
  <nav role="navigation" class="menu bottom-menu">
    <ul class="menu-item">
      
      
        
      
      <li><a href="http://vitess.io/" >Home</a></li>
      
      
        
      
      <li><a href="http://vitess.io/getting-started/" >Getting Started</a></li>
      
      
        
      
      <li><a href="http://vitess.io/about/" >About</a></li>
      
      
        
      
      <li><a href="http://vitess.io/faq/" >FAQ</a></li>
      
      
        
      
      <li><a href="http://vitess.io/terms/" >Terms</a></li>
      
    </ul>
  </nav>
  <p class="copyright">&#169; 2015 <a href="http://vitess.io">Vitess</a> powered by <a href="http://www.google.com">Google Inc</a>.</p>
</footer>

    </div>

    <script src="http://vitess.io/js/vendor/jquery-1.9.1.min.js"></script>
    <script src="http://vitess.io/js/main.js"></script>
    
    
    <script type="text/javascript">
      $('.toc').toc({
        'selectors': 'h2', //elements to use as headings
        'container': '.page-content', //element to find all selectors in
        'smoothScrolling': true, //enable or disable smooth scrolling on click
        'prefix': 'toc', //prefix for anchor tags and class names
        'onHighlight': function(el) {}, //called when a new section is highlighted 
        'highlightOnScroll': true, //add class to heading that is currently in focus
        'highlightOffset': 100, //offset to trigger the next headline
        'anchorName': function(i, heading, prefix) { //custom function for anchor name
          return prefix+i;
        },
        'headerText': function(i, heading, $heading) { //custom function building the header-item text
          return $heading.text();
        },
        'itemClass': function(i, heading, $heading, prefix) { //custom function for item class
          return $heading[0].tagName.toLowerCase();
        }
      });
    </script>
    
    <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-60219601-1', 'auto');
  ga('send', 'pageview');
</script>

  </body>
</html>
